<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>David Paulius, Ph.D. | Personal Website</title>
    <link>https://davidpaulius.github.io/</link>
    <description>Recent content on David Paulius, Ph.D. | Personal Website</description>
    <generator>Hugo -- 0.147.8</generator>
    <language>en</language>
    <copyright>2025 David Paulius</copyright>
    <lastBuildDate>Tue, 20 May 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://davidpaulius.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bootstrapping Object-level Planning with Large Language Models</title>
      <link>https://davidpaulius.github.io/papers/olp-icra25/</link>
      <pubDate>Tue, 20 May 2025 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/olp-icra25/</guid>
      <description>TL;DR &amp;ndash; This paper formalizes the concept of object-level planning and discusses how this level of planning naturally integrates with large language models (LLMs).</description>
    </item>
    <item>
      <title>Lang2LTL-2: Grounding Spatiotemporal Navigation Commands Using Large Language and Vision-Language Models</title>
      <link>https://davidpaulius.github.io/papers/IROS24_spatiotemp/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/IROS24_spatiotemp/</guid>
      <description>TL;DR &amp;ndash; Building on prior work (Lang2LTL - CoRL 2023), this paper introduces a modular system that enables robots to follow natural language commands with spatiotemporal referring expressions. This system leverages multi-modal foundation models as well as the formal language LTL (linear temporal logic).</description>
    </item>
    <item>
      <title>CAPE: Corrective Actions from Precondition Errors using Large Language Models</title>
      <link>https://davidpaulius.github.io/papers/cape/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/cape/</guid>
      <description>TL;DR &amp;ndash; In this paper, we introduce CAPE: an approach to correct errors encountered during robot plan execution. We exploit the ability of large language models to generate high-level plans and to reason about causes of errors.</description>
    </item>
    <item>
      <title>Skill Generalization With Verbs</title>
      <link>https://davidpaulius.github.io/papers/IROS23_skill_gen/</link>
      <pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/IROS23_skill_gen/</guid>
      <description>TL;DR &amp;ndash; This paper introduces a deep learning-based method for learning about the effects of verbs &amp;ndash; more specifically, looking at initiation and termination conditions as with Markov Decision Processes (MDPs).</description>
    </item>
    <item>
      <title>Long-Horizon Planning and Execution with Functional Object-Oriented Networks</title>
      <link>https://davidpaulius.github.io/papers/foon_lhpe/</link>
      <pubDate>Tue, 13 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/foon_lhpe/</guid>
      <description>TL;DR &amp;ndash; In this paper, we introduce the idea of connecting FOONs to robotic task and motion planning. We automatically transform a FOON graph, which exists at the object level (i.e., it is a representation that uses meaningful labels or expressions close to human language), into task planning specifications written in PDDL (not a very intuitive way to communicate about tasks).</description>
    </item>
    <item>
      <title>Object-Level Planning and Abstraction</title>
      <link>https://davidpaulius.github.io/papers/olp_bluesky/</link>
      <pubDate>Wed, 14 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/olp_bluesky/</guid>
      <description>TL;DR &amp;ndash; This workshop paper (specifically, a blue-sky submission) introduces the importance of object-level planning and representation as an additional layer on top of task and motion planning. I present several benefits of using object-level planning for long-term use in robotics.</description>
    </item>
    <item>
      <title>Approximate Task Tree Retrieval in a Knowledge Network for Robotic Cooking</title>
      <link>https://davidpaulius.github.io/papers/foon_tree_retrieval/</link>
      <pubDate>Fri, 15 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/foon_tree_retrieval/</guid>
      <description>TL;DR &amp;ndash; In this paper, we introduce the idea of connecting FOONs to robotic task and motion planning. We automatically transform a FOON graph, which exists at the object level (i.e., it is a representation that uses meaningful labels or expressions close to human language), into task planning specifications written in PDDL (not a very intuitive way to communicate about tasks).</description>
    </item>
    <item>
      <title>Robot Learning of Assembly Tasks from Non-expert Demonstrations using Functional Object-Oriented Network</title>
      <link>https://davidpaulius.github.io/papers/foon_assembly/</link>
      <pubDate>Fri, 15 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/foon_assembly/</guid>
      <description>TL;DR &amp;ndash; This was a collaboration with Clemson University&amp;rsquo;s Yunyi Jia and Yi Chen, who were interested in using FOONs for representing assembly tasks. They successfully utilized and adapted a FOON to robotic assembly execution.</description>
    </item>
    <item>
      <title>Leben in MÃ¼nchen: A Reflection of my Year Living in Munich</title>
      <link>https://davidpaulius.github.io/blog/muenchen/</link>
      <pubDate>Mon, 15 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/blog/muenchen/</guid>
      <description>This template produces a minimalist academic presentation with LaTeX Beamer.</description>
    </item>
    <item>
      <title>Task Planning with a Weighted Functional Object-Oriented Network</title>
      <link>https://davidpaulius.github.io/papers/foon_cobot/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/foon_cobot/</guid>
      <description>TL;DR &amp;ndash; In this paper, we attempt to execute task plan sequences extracted from FOONs. However, these sequences may contain actions that are not executable by a robot. Therefore, a human is introduced in the planning and execution loop, and both the robot and human assistant work together to solve the task.</description>
    </item>
    <item>
      <title>Developing Motion Code Embedding for Action Recognition in Videos</title>
      <link>https://davidpaulius.github.io/papers/motion_codes_ICPR20/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/motion_codes_ICPR20/</guid>
      <description>TL;DR &amp;ndash; This work uses the features from the motion taxonomy to improve action recognition on egocentric videos from the EPIC-KITCHENS dataset. This is done by integrating motion code detection for action sequences.</description>
    </item>
    <item>
      <title>Estimating Motion Codes from Demonstration Videos</title>
      <link>https://davidpaulius.github.io/papers/motion_codes_IROS20/</link>
      <pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/motion_codes_IROS20/</guid>
      <description>TL;DR &amp;ndash; In this work, we showed how motion codes (which can be constructed using the motion taxonomy proposed in our RSS 2020 paper) can be used to improve action recognition with deep neural networks.</description>
    </item>
    <item>
      <title>A Motion Taxonomy for Manipulation Embedding</title>
      <link>https://davidpaulius.github.io/papers/motion_codes_RSS20/</link>
      <pubDate>Wed, 15 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/motion_codes_RSS20/</guid>
      <description>TL;DR &amp;ndash; In this work, we introduce new changes to the features of the motion taxonomy and show how action verbs encoded as motion codes better capture differences between them than conventional word embedding (as word2vec).</description>
    </item>
    <item>
      <title>Giving Thanks</title>
      <link>https://davidpaulius.github.io/blog/phd-gratitude/</link>
      <pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/blog/phd-gratitude/</guid>
      <description>My dedication and acknowledgements to everyone that supported me during my Ph.D. journey.</description>
    </item>
    <item>
      <title>Manipulation Motion Taxonomy and Coding for Robots</title>
      <link>https://davidpaulius.github.io/papers/motion_codes_IROS19/</link>
      <pubDate>Sun, 03 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/motion_codes_IROS19/</guid>
      <description>TL;DR &amp;ndash; This paper introduces the motion taxonomy, a collection of robot-relevant features that are better suited for verb or action embedding than conventional word embedding. Motion codes are constructed per verb using the taxonomy. In this work, we show that motion codes assigned to verbs are closely related to one another based on force and trajectory data.</description>
    </item>
    <item>
      <title>A Survey of Knowledge Representation in Service Robotics</title>
      <link>https://davidpaulius.github.io/papers/survey_kr/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/survey_kr/</guid>
      <description>TL;DR &amp;ndash; This was my first survey paper that covers knowledge representations for service robotics. Although it is dated, it covers an extensive list of approaches used to represent knowledge for several robot sub-tasks.</description>
    </item>
    <item>
      <title>Long Activity Video Understanding using Functional Object-Oriented Network</title>
      <link>https://davidpaulius.github.io/papers/foon_video_understanding/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/foon_video_understanding/</guid>
      <description>TL;DR &amp;ndash; This work leverages functional object-oriented networks and deep learning for video understanding. In addition, with the deep network framework, we jointly recognize object and action types, which can then be used for constructing new FOON structures.</description>
    </item>
    <item>
      <title>Functional Object-Oriented Network: Construction &amp; Expansion</title>
      <link>https://davidpaulius.github.io/papers/foon_gen_exp/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/foon_gen_exp/</guid>
      <description>TL;DR &amp;ndash; In this paper, we explore methods in natural language processing (NLP) &amp;ndash; specifically semantic similarity &amp;ndash; for expanding or generalizing knowledge contained in a FOON. This alleviates the need for demonstrating and annotating graphs by other means.</description>
    </item>
    <item>
      <title>Functional Object-Oriented Network for Manipulation Learning</title>
      <link>https://davidpaulius.github.io/papers/foon_intro/</link>
      <pubDate>Sat, 15 Oct 2016 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/papers/foon_intro/</guid>
      <description>TL;DR &amp;ndash; This was the very first paper on FOON: the functional object-oriented network. Here, we introduced what they are and how they can be used for task planning. They are advantageous for their flexibility and human interpretability.</description>
    </item>
    <item>
      <title>About Me ð¤</title>
      <link>https://davidpaulius.github.io/etcetera/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/etcetera/about/</guid>
      <description>This is an overview of David Paulius, Ph.D.</description>
    </item>
    <item>
      <title>Academic Philosophy</title>
      <link>https://davidpaulius.github.io/academia/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/academia/</guid>
      <description>&lt;h3 id=&#34;note-featured-here-are-documents-for-faculty-applications&#34;&gt;NOTE: Featured here are documents for Faculty Applications.&lt;/h3&gt;
&lt;h4 id=&#34;my-role-as-an-academic&#34;&gt;My Role as an Academic&lt;/h4&gt;
&lt;p&gt;I seek to use my academic gifts and talents to solve every-day problems using &lt;em&gt;robotics and artificial intelligence (AI)&lt;/em&gt;, particularly for peoples, communities or groups in need. Such robots must efficiently and safely operate around and collaborate with humans.&lt;/p&gt;
&lt;p&gt;My journey into an academic role was inspired by my mentors (both in my undergraduate and graduate studies) as well as prominent researchers in robotics.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Curriculum Vitae</title>
      <link>https://davidpaulius.github.io/cv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/cv/</guid>
      <description>&lt;hr&gt;
&lt;h3 id=&#34;note-redirecting-to-cv&#34;&gt;NOTE: Redirecting to CV&amp;hellip;&lt;/h3&gt;
&lt;h4 id=&#34;if-this-page-does-not-redirect-please-use-this-link&#34;&gt;If this page does not redirect, please use this &lt;a href=&#34;https://drive.google.com/file/d/18anG-rgWd6nU4ajJYlvwcPFUxxXIDz2b/view&#34; target=&#34;_blank&#34;&gt;link &lt;/a&gt;.&lt;/h4&gt;
&lt;meta http-equiv=&#34;refresh&#34; content=&#34;0; url=https://drive.google.com/file/d/18anG-rgWd6nU4ajJYlvwcPFUxxXIDz2b/view&#34; /&gt;</description>
    </item>
    <item>
      <title>Fun Stuff ð</title>
      <link>https://davidpaulius.github.io/etcetera/fun/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/etcetera/fun/</guid>
      <description>This is an overview of David Paulius, Ph.D.</description>
    </item>
    <item>
      <title>Latest News &amp; Timeline</title>
      <link>https://davidpaulius.github.io/news/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/news/</guid>
      <description>My Latest Updates</description>
    </item>
    <item>
      <title>Photography ð¸</title>
      <link>https://davidpaulius.github.io/etcetera/photography/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://davidpaulius.github.io/etcetera/photography/</guid>
      <description>Check out some of my favourite shots here!</description>
    </item>
  </channel>
</rss>
